High throughput sequencing (HTS) machines output thousands to billions of `reads', short nucleotide sequences that are derived from a DNA or RNA molecule in the sequencing `library'. The library is a subset of the nucleic acid molecules that have been collected from an environment and made compatible with a particular HTS platform. The HTS instruments deliver these reads as integer `counts' per genomic feature---gene, location, etc. However, the counts are actually a single proxy for the probability of observing the particular read in a sample under a repeated sampling model; this is clear since technical replicates of the same library return different counts. The difference between technical replicates is consistent with multivariate Poisson sampling \citep{fernandes:2013, gloorAJS:2016} The probability estimate is delivered by the instrument as an integer representation of the probability multiplied by the number of reads  \citep{fernandes:2013, gloorAJS:2016}. Thus, the data returned by HTS are a type of count compositional data, where only the relationships between the features have meaning \citep{aitchison:1986, Lovell:2015,fernandes:2014,gloorFrontiers:2017,Kaul:2017aa}. 

The ALDEx2 tool uses a combination of probabilistic modelling and compositional data analysis to determine the features that are different between groups, where that difference is insensitive to random sampling. Technical replicate variance estimation and conversion of the count data to probabilities is accomplished by Monte-Carlo sampling from the Dirichlet distribution \citep{fernandes:2013, gloorAJS:2016}, which is conveniently also the conjugate prior for the multivariate Poisson process. The differences between features is linearized by applying a log-ratio transformation to the Dirichlet Monte-Carlo realizations and analyzed according to the rules of compositional data analysis \citep{aitchison:1986,fernandes:2013,Tsilimigras:2016aa,gloorFrontiers:2017}.
	
Starting with two vectors $\vec{a}$ and $\vec{b}$  that correspond to the concatenated log-ratio transformed Dirichlet Monte-Carlo realizations of a feature in two groups, we need a method to determine the standardized effect size  for the log-ratio transformed posterior probability estimates;  that is, the difference between groups relative to an estimate of within-group dispersion. Since these posterior distributions can have heavy tails, be multimodal, and be skewed, any useful statistic should be insensitive to even extreme non-Normality and provide sensible answers even if the posterior picture distributions are almost Cauchy in one or both groups \citep{fernandes:2013}. Below and in the Supplement we define the properties of the approach used. 

Cohen's d is a parametric standardized effect size for the difference between the means of two groups, and a general formulation is given in Equation~\ref{eq:cohen}. Cohen's d is the difference between the means of the two distributions divided by the pooled standard deviation, denoted as \(\sigma_{a,b}\). However, this metric depends upon the data being relatively Normal, which cannot be guaranteed for HTS data. 

\begin{equation}
\mathrm{d} = \frac{\mathrm{mean}(\vec{a} )- \mathrm{mean}(\vec{b})}{\sigma_{a,b}}
\label{eq:cohen}
\end{equation}

We can define a non-parametric  \emph{difference} vector  in Equation~(\ref{eq:diff}) as the signed difference between the two groups. We can further define a non-parametric  \emph{dispersion} vector as in Equation~(\ref{eq:disp}), where the notation $\boldsymbol{\rho}\vec{a}$ indicates one or more random permutations of the vector. Finally, we can define an \emph{effect} vector as in Equation~(\ref{eq:ff}) that is the ratio of these two non-parametric statistics. 

\begin{equation}
\vec{\delta} = \vec{a} - \vec{b}
\label{eq:diff}\vspace*{-10pt}
\end{equation}

\begin{equation}
\vec{\sigma} = max \{ \lvert \vec{a} - \boldsymbol{\rho} \vec{a}  \rvert ,\lvert \vec{b} -\boldsymbol{\rho} \vec{b} \rvert \}
\label{eq:disp}\vspace*{-10pt}
\end{equation}

\begin{equation}
\vec{\varepsilon} = \frac{\vec{\delta}}{\vec{\sigma}}
\label{eq:ff}\vspace*{0pt}
\end{equation}

Taking the median of $\vec{\delta}, \vec{\sigma}$ and $\vec{\varepsilon}$ returns a robust estimate of the central tendency of these statistics ($\tilde{D}$, MMAD (median of the maximum absolute deviation), and $\mathcal{E}_{d}$), and these are the `diff.btw', `diff.win' and `effect' statistics reported by ALDEx2. $\tilde{D}$ is the same as the difference between the means or the difference between medians in a Normal distribution as shown in Supplementary Figure  2. The MMAD metric is novel and the Supplement shows it has a Gaussian efficiency of 52\%, a breakdown point of 20\% (Supplementary Figure 3), and is 1.42 times the size of the standard deviation on a Normal distribution. The $\mathcal{E}_{d}$ statistic is a standardized effect size and is approximately 0.7 of Cohen's D when comparing the difference between two Normal distributions.  This is simply a Monte-Carlo estimate of a function of the respective random variables. Below and in Supplementary Figure 4 we show that this metric returns sensible values even with a Cauchy distribution.
